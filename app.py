"""The main module of the app.

Contains the corpus of the app and the main function `modelisation`.
This function create train the model,
also plot the losses and show the reconstructed images.
"""

import streamlit as st
import matplotlib.pyplot as plt
import torch
import os

# Import modules
from vae import VAE
from bvae import BetaVAE
from svae import SigmaVAE
from train import train_model
from utils import get_dataset, generate_model_id
from viz import (
    visualize_reconstructions,
    generate_samples,
    plot_loss_interactive,
    create_vae_diagram,
)

# Configuration de la page
st.set_page_config(
    page_title="Variational Autoencoder Explorer", page_icon="üñº", layout="wide"
)

# Assurez-vous que le dossier 'models' existe
if not os.path.exists("models"):
    os.makedirs("models")

# Structure principale de l'application avec deux colonnes
col1, col2 = st.columns([3, 1])


# Fonction pour cr√©er et entrainer le mod√®le ou charger un mod√®le existant
def modelisation(
    model_name,
    dataset,
    latent_dim,
    hidden_layers,
    reconstruction_error,
    beta,
    batch_size,
    epochs,
):
    # Cr√©ation du dataloader
    train_loader, test_loader, dim = get_dataset(dataset, batch_size)

    # Param√®tres du mod√®le pour identifier les mod√®les d√©j√† entra√Æn√©s
    model_params = {
        "model_name": model_name,
        "dataset": dataset,
        "latent_dim": latent_dim,
        "hidden_layers": hidden_layers,
        "reconstruction_error": reconstruction_error,
        "epochs": epochs,
    }

    model_id = generate_model_id(model_params)
    model_path = f"models/vae_{model_id}.pth"
    losses_path = f"models/vae_{model_id}_losses.pth"

    # Cr√©ation du mod√®le VAE
    c, w, h = dim
    if model_name == "VAE classique":
        model = VAE(
            c,
            w,
            h,
            latent_dim=latent_dim,
            hidden_dims=hidden_layers,
            recon_loss_type=reconstruction_error,
        )
    elif model_name == "Œ≤-VAE":
        model = BetaVAE(
            c,
            w,
            h,
            latent_dim=latent_dim,
            hidden_dims=hidden_layers,
            recon_loss_type=reconstruction_error,
            beta=beta,
        )
    elif model_name == "œÉ-VAE":
        model = SigmaVAE(
            c,
            w,
            h,
            latent_dim=latent_dim,
            hidden_dims=hidden_layers,
            recon_loss_type=reconstruction_error,
            beta=beta,
        )

    # V√©rifier si le mod√®le existe d√©j√†
    if os.path.exists(model_path) and os.path.exists(losses_path):
        st.info("Chargement d'un mod√®le existant avec les m√™mes param√®tres...")

        # Charger le mod√®le et les historiques de perte
        model.load_state_dict(torch.load(model_path, map_location=torch.device("cpu")))
        losses = torch.load(losses_path, map_location=torch.device("cpu"))

        # Afficher le r√©capitulatif des pertes
        st.subheader("Fonction de perte et reconstruction")
        loss_fig = plt.figure(figsize=(10, 6))
        plot_loss_interactive(
            losses["train_losses"], losses["test_losses"], fig=loss_fig
        )
        st.pyplot(loss_fig)
        plt.close(loss_fig)

        recon_fig = plt.figure(figsize=(10, 4))
        visualize_reconstructions(model, test_loader, fig=recon_fig)
        st.pyplot(recon_fig)
        plt.close(recon_fig)

        # Afficher message de confirmation
        st.success(f"Mod√®le charg√© avec succ√®s! (Nombre d'epochs: {epochs})")

        # Afficher les images g√©n√©r√©es
        st.subheader("Images g√©n√©r√©es")
        fig_gen = plt.figure(figsize=(10, 10))
        generate_samples(model, num_samples=16, fig=fig_gen)
        st.pyplot(fig_gen)
        plt.close(fig_gen)
    else:
        # Pr√©paration des √©l√©ments d'affichage pour l'entra√Ænement
        st.subheader("Entra√Ænement du mod√®le")
        progress_bar = st.progress(0)
        status_text = st.empty()

        # Placeholder pour les pertes et reconstructions pendant l'entra√Ænement
        loss_placeholder = st.empty()
        images_placeholder = st.empty()

        # Entrainement du mod√®le
        trained_model, losses = train_model(
            model=model,
            train_loader=train_loader,
            test_loader=test_loader,
            num_epochs=epochs,
            progress_bar=progress_bar,
            status_text=status_text,
            loss_placeholder=loss_placeholder,
            images_placeholder=images_placeholder,
        )

        # Sauvegarder le mod√®le entra√Æn√© et les historiques de pertes
        torch.save(model.state_dict(), model_path)
        torch.save(losses, losses_path)

        # Afficher un message de fin d'entrainement
        st.success(
            f"Entrainement termin√© apr√®s {epochs} epochs! Mod√®le sauvegard√© dans {model_path}"
        )

        # Afficher les images g√©n√©r√©es une fois l'entra√Ænement termin√©
        st.subheader("Images g√©n√©r√©es")
        fig_gen = plt.figure(figsize=(10, 10))
        generate_samples(model, num_samples=16, fig=fig_gen)
        st.pyplot(fig_gen)
        plt.close(fig_gen)

    return model


# Sidebar pour les hyperparam√®tres
st.sidebar.title("Param√®tres du VAE")

# S√©lection du model
model_name = st.sidebar.selectbox("Type de VAE", ["VAE classique", "Œ≤-VAE", "œÉ-VAE"])

# S√©lection du dataset
dataset = st.sidebar.selectbox("Dataset", ["MNIST", "CIFAR10"])

# Dimension de l'espace latent
latent_dim = st.sidebar.slider(
    "Dimension de l'espace latent", min_value=2, max_value=200, value=40, step=1
)

# Couches convolutionnelles cach√©es
hidden_layers = st.sidebar.multiselect(
    "Couches convolutionnelles cach√©es",
    options=[8, 16, 32, 64, 128, 256, 512],
    default=[32, 64],
)

# V√©rifier si le nombre de s√©lections d√©passe le maximum autoris√©
if len(hidden_layers) > 5:
    st.sidebar.error(
        "Vous ne pouvez s√©lectionner qu'un maximum de 5 couches de convolution."
    )
    # R√©initialiser la s√©lection si n√©cessaire
    hidden_layers = hidden_layers[:5]

# V√©rifier si le nombre de s√©lections est d'au moins 1
if len(hidden_layers) == 0:
    st.sidebar.error("Vous devez choisir au moins une couche de convolution.")
    # R√©initialiser la s√©lection si n√©cessaire
    hidden_layers = [32]

# Type d'erreur de reconstruction
if model_name == "œÉ-VAE":
    reconstruction_error = st.sidebar.selectbox(
        "Erreur de reconstruction (log-vraissemblance)", ["gaussian", "laplace"]
    )
else:
    reconstruction_error = st.sidebar.selectbox(
        "Erreur de reconstruction", ["MSE", "L1"]
    )

if model_name != "VAE classique":
    beta = st.sidebar.slider(
        "Coefficient de la KL divergence Œ≤",
        min_value=0.1,
        max_value=2.0,
        value=0.5,
        step=0.1,
    )
else:
    beta = 1

# Taille du batch
batch_size = st.sidebar.selectbox("Taille du batch", options=[64, 128, 256], index=0)

# Nombre d'epochs
epochs = st.sidebar.slider(
    "Nombre d'epochs", min_value=1, max_value=50, value=5, step=1
)

if dataset.lower() == "mnist":
    st.sidebar.info(
        """
    **MNIST** : 60 000 images d'entra√Ænement et 10 000 images de test
    de chiffres manuscrits (0-9) en noir et blanc de dimensions 1 canaux et 28x28 pixels.
    """
    )
if dataset.lower() == "cifar10":
    st.sidebar.info(
        """
    **Cifar10** : 50 000 images d'entra√Ænement et 10 000 images de test
    reparti en 10 classes (avion, automobile, oiseau, chat, cerf, chien, grenouille, bateau, camion) en couleur
    de dimensions 3 canaux et 32x32 pixels.
    """
    )

# Colonne 1: Contenu principal
with col1:
    st.title("Explorateur de Variational Autoencoder (VAE)")
    st.write(
        """
    Cette application permet d'explorer les Variational Autoencoders (VAEs), un type de mod√®le g√©n√©ratif
    qui apprend √† reconstruire et g√©n√©rer des images √† partir d'un espace latent continu.
    Ajustez les param√®tres dans la barre lat√©rale et lancez l'entrainement pour observer les r√©sultats.
    """
    )

    # Section "En savoir plus sur les VAE"
    with st.expander("En savoir plus sur les VAE"):
        st.write(
            """
        ### Qu'est-ce qu'un Variational Autoencoder (VAE)?

        Un Variational Autoencoder est un type de r√©seau de neurones g√©n√©ratif qui apprend √† repr√©senter des donn√©es
        dans un espace latent continu. Contrairement aux autoencoders classiques, les VAEs imposent une structure sur
        l'espace latent en utilisant une approche probabiliste.

        ### Architecture

        Un VAE se compose de deux parties principales:

        1. **Encodeur**: Transforme les donn√©es d'entr√©e en distributions dans l'espace latent (moyenne Œº et variance œÉ¬≤)
        2. **D√©codeur**: Reconstruit les donn√©es √† partir d'√©chantillons de l'espace latent

        ### Fonction de perte

        La fonction de perte d'un VAE comprend deux termes:

        - **Erreur de reconstruction**: Mesure la diff√©rence entre les donn√©es d'entr√©e et leur reconstruction
        - **Divergence KL**: Force la distribution latente √† se rapprocher d'une distribution normale standard

        La fonction de perte totale est: L = Reconstruction_Loss + Œ≤ * KL_Divergence

        ### G√©n√©ration de nouvelles donn√©es

        Apr√®s l'entrainement, on peut g√©n√©rer de nouvelles donn√©es en:
        1. √âchantillonnant des points de l'espace latent suivant N(0, I)
        2. D√©codant ces points en utilisant le d√©codeur

        ### Applications

        Les VAEs sont utilis√©s pour:
        - La g√©n√©ration d'images
        - La compression de donn√©es
        - L'apprentissage de repr√©sentations
        - L'interpolation entre diff√©rentes donn√©es
        """
        )

    # Bouton pour lancer l'entrainement
    if st.button("Entrainer le mod√®le"):
        with st.spinner("Entrainement/chargement du mod√®le en cours..."):
            trained_model = modelisation(
                model_name=model_name,
                dataset=dataset,
                latent_dim=latent_dim,
                hidden_layers=hidden_layers,
                reconstruction_error=reconstruction_error,
                beta=beta,
                batch_size=batch_size,
                epochs=epochs,
            )

# Colonne 2: Sch√©ma du VAE (toujours visible)
with col2:
    st.markdown(4 * "<br>", unsafe_allow_html=True)
    st.subheader("Architecture")

    # D√©terminer le nombre de canaux bas√© sur le dataset s√©lectionn√©
    dim = (1, 28, 28) if dataset.lower() == "mnist" else (3, 32, 32)

    # Cr√©er et afficher le sch√©ma du VAE qui est interactif avec les param√®tres
    vae_diagram = create_vae_diagram(
        input_dim=dim, latent_dim=latent_dim, hidden_dims=hidden_layers
    )
    st.graphviz_chart(vae_diagram)

    # Section R√©f√©rences
    st.markdown("---")
    st.subheader("R√©f√©rences")
    st.markdown(
        """
    - [Auto-Encoding Variational Bayes](https://arxiv.org/abs/1312.6114) - Diederik P. Kingma, Max Welling (2013)
    - [Tutorial on Variational Autoencoders](https://arxiv.org/abs/1606.05908) - Carl Doersch (2016)
    """
    )

    # Footer
    st.markdown("---")
    st.markdown(
        "D√©velopp√©e par Lylian Challier et Mohamed-Amine Grini avec Streamlit et Pytorch."
    )
    st.markdown("[Repository GitHub du projet](https://github.com/LylianChallier/VAEs)")
